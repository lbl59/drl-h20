{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Source: https://github.com/DLR-RM/stable-baselines3\n",
    "SB3 Documentation: https://stable-baselines3.readthedocs.io/en/master/\n",
    "PPO Documentation: https://stable-baselines3.readthedocs.io/en/master/modules/ppo.html#\n",
    "'''\n",
    "import gym\n",
    "from stable_baselines3 import PPO\n",
    "import numpy as np\n",
    "import imageio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Pong-v0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# view all available environments\n",
    "from gym import envs\n",
    "env_names = [spec.id for spec in envs.registry.all()]\n",
    "'''\n",
    "for name in sorted(env_names):\n",
    "    print(name)\n",
    "'''\n",
    "env_names[700]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make the gym environment\n",
    "# prevent the pole from falling off the cart!\n",
    "#env_cartpole = gym.make(\"CartPole-v1\")\n",
    "env_mtcar = gym.make('MountainCar-v0')\n",
    "#env_pendulum = gym.make('Pendulum-v1', g=9.81)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 200      |\n",
      "|    ep_rew_mean     | -200     |\n",
      "| time/              |          |\n",
      "|    fps             | 1914     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 1        |\n",
      "|    total_timesteps | 2048     |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 200          |\n",
      "|    ep_rew_mean          | -200         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1311         |\n",
      "|    iterations           | 2            |\n",
      "|    time_elapsed         | 3            |\n",
      "|    total_timesteps      | 4096         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0011669234 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.1         |\n",
      "|    explained_variance   | 0.000638     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 15.5         |\n",
      "|    n_updates            | 10           |\n",
      "|    policy_gradient_loss | -0.000209    |\n",
      "|    value_loss           | 136          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 200         |\n",
      "|    ep_rew_mean          | -200        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1209        |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 5           |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002906255 |\n",
      "|    clip_fraction        | 0           |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.1        |\n",
      "|    explained_variance   | -0.0505     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 13.2        |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.000642   |\n",
      "|    value_loss           | 90          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 200         |\n",
      "|    ep_rew_mean          | -200        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1178        |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 6           |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008816327 |\n",
      "|    clip_fraction        | 0.00205     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.09       |\n",
      "|    explained_variance   | -0.0207     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 17.1        |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.000999   |\n",
      "|    value_loss           | 85          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 200         |\n",
      "|    ep_rew_mean          | -200        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1159        |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 8           |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014638592 |\n",
      "|    clip_fraction        | 0.0105      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.05       |\n",
      "|    explained_variance   | 0.00239     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 13          |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.00106    |\n",
      "|    value_loss           | 70          |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<stable_baselines3.ppo.ppo.PPO at 0x2bd10821d30>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# setup the model \n",
    "# Implement actor critic, using a multi-layer perceptron (2 layers of 64) in the \n",
    "# pre-specified environment\n",
    "# set verbose = 1 to print out the infor messages\n",
    "model = PPO(\"MlpPolicy\", env_mtcar, verbose=1)\n",
    "# return a trained model that is trained over 10,000 timesteps\n",
    "model.learn(total_timesteps=10_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the environment\n",
    "vec_env = model.get_env()\n",
    "# reset the environment and return an array of observations whenever a new episode is started\n",
    "# (or a tuple of observation arrays)\n",
    "obs = vec_env.reset()\n",
    "img = model.env.render(mode='rgb_array')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i= 0\n",
      "Observations= [[-4.9897873e-01 -1.8587272e-04]]\n",
      "Rewards= [-1.]\n",
      "Done? [False]\n",
      "Info= [{}]\n",
      "i= 500\n",
      "Observations= [[-0.5108848   0.00085479]]\n",
      "Rewards= [-1.]\n",
      "Done? [False]\n",
      "Info= [{}]\n",
      "i= 1000\n",
      "Observations= [[-5.129934e-01 -8.012777e-05]]\n",
      "Rewards= [-1.]\n",
      "Done? [False]\n",
      "Info= [{}]\n",
      "i= 1500\n",
      "Observations= [[-0.532701  -0.0006113]]\n",
      "Rewards= [-1.]\n",
      "Done? [False]\n",
      "Info= [{}]\n",
      "i= 2000\n",
      "Observations= [[-4.7389671e-01 -3.7416062e-04]]\n",
      "Rewards= [-1.]\n",
      "Done? [False]\n",
      "Info= [{}]\n",
      "i= 2500\n",
      "Observations= [[-0.46782857  0.00391052]]\n",
      "Rewards= [-1.]\n",
      "Done? [False]\n",
      "Info= [{}]\n",
      "i= 3000\n",
      "Observations= [[-4.6665838e-01 -4.2814304e-04]]\n",
      "Rewards= [-1.]\n",
      "Done? [False]\n",
      "Info= [{}]\n",
      "i= 3500\n",
      "Observations= [[-0.555709  -0.0021852]]\n",
      "Rewards= [-1.]\n",
      "Done? [False]\n",
      "Info= [{}]\n",
      "i= 4000\n",
      "Observations= [[-4.9956194e-01 -1.8147765e-04]]\n",
      "Rewards= [-1.]\n",
      "Done? [False]\n",
      "Info= [{}]\n",
      "i= 4500\n",
      "Observations= [[-0.51497906  0.00057882]]\n",
      "Rewards= [-1.]\n",
      "Done? [False]\n",
      "Info= [{}]\n"
     ]
    }
   ],
   "source": [
    "images = []\n",
    "for i in range(5000):\n",
    "    images.append(img)\n",
    "    # get the policy action from an observation and the optional hidden state\n",
    "    # return the deterministic actions \n",
    "    action, _states = model.predict(obs, deterministic=True)\n",
    "    # step the envrionment with the given action\n",
    "    # return the observation, reward, whether th \n",
    "    obs, rewards, done, info = vec_env.step(action)\n",
    "    img = model.env.render(mode='rgb_array')\n",
    "    if (i%500) == 0:\n",
    "        print(\"i=\", i)\n",
    "        print(\"Observations=\", obs)\n",
    "        print(\"Rewards=\", rewards)   \n",
    "        print(\"Done?\", done)\n",
    "        print(\"Info=\", info)\n",
    "\n",
    "    vec_env.render()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "imageio.mimsave('mtcart.gif', [np.array(img) for i, img in enumerate(images) if i%2 == 0], fps=29)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec_env.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
